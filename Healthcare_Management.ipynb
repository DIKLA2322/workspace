{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import all necessary Library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=20, threshold=10, linewidth=40)  # np forbids scientific counting\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)  # pd forbids scientific counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/train_data.csv\"\n",
    "\n",
    "df_all = pd.read_csv(path)  # Read the data according to your own file address\n",
    "\n",
    "df_all.drop_duplicates(\n",
    "    inplace=True)  # drop_duplicates are used to perform deduplication, and inplace=True replaces the original data set\n",
    "df_all.reset_index(drop=True, inplace=True)  # After deleting the data, restore the index\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at data types and missing cases as a whole\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Hospital_code'] = df_all['Hospital_code'].astype(object)\n",
    "df_all['City_Code_Hospital'] = df_all['City_Code_Hospital'].astype(object)\n",
    "df_all['Bed Grade'] = df_all['Bed Grade'].astype(object)\n",
    "df_all['City_Code_Patient'] = df_all['City_Code_Patient'].astype(object)\n",
    "df_all['Hospital_code'] = df_all['Hospital_code'].astype(float)\n",
    "df_all['Available Extra Rooms in Hospital'] = df_all['Available Extra Rooms in Hospital'].astype(float)\n",
    "df_all['patientid'] = df_all['patientid'].astype(float)\n",
    "df_all['Visitors with Patient'] = df_all['Visitors with Patient'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find missing variables and return a list of missing value rate > specified missing rate (narate)\n",
    "def filter_col_by_nan(data, narate=0.2):\n",
    "    '''\n",
    "    :param data: 查找数据集\n",
    "    :param narate: 设定变量的缺失值率\n",
    "    :return: 返回 缺失率>narate的变量名称列表\n",
    "    '''\n",
    "    n_samples = data.shape[0]\n",
    "    list_nan_cols = []\n",
    "    for col in data.columns:\n",
    "        if data[col].isna().sum() / n_samples >= (narate):\n",
    "            list_nan_cols.append(col)\n",
    "    print(f'Variables with more than {narate * 100}% missing are: {list_nan_cols}')\n",
    "    return list_nan_cols\n",
    "\n",
    "\n",
    "list_nullfactor_todrop = filter_col_by_nan(df_all, narate=0.3)\n",
    "df_select = df_all.drop(list_nullfactor_todrop, axis=1).copy()\n",
    "df_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select['Stay'].replace('More than 100 Days', '>100', inplace=True)\n",
    "\n",
    "for i in ['Stay', 'Department', 'Available Extra Rooms in Hospital', 'Ward_Type', 'Ward_Facility_Code', 'Age',\n",
    "          'Type of Admission', 'Severity of Illness', 'Bed Grade', 'Hospital_region_code', 'Hospital_type_code',\n",
    "          'City_Code_Hospital', 'Hospital_code', 'City_Code_Patient', 'Visitors with Patient']:\n",
    "    count = df_select[i].value_counts()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=count.index.values, y=count.values, data=df_select)\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in ['Department', 'Ward_Type', 'Ward_Facility_Code', 'Age', 'Type of Admission', 'Severity of Illness',\n",
    "          'Bed Grade', 'Hospital_region_code', 'Hospital_type_code']:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    sns.countplot(x='Stay', hue=i, data=df_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_select['Admission_Deposit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(data, columns):\n",
    "    for column in columns:\n",
    "        data[column] = data[column].fillna(data[column].value_counts().index[0])\n",
    "        print(data[column].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_columns = ['Bed Grade', 'City_Code_Patient']\n",
    "impute_missing_values(df_select, impute_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_encode = {'Trauma': 1, 'Urgent': 2, 'Emergency': 3}\n",
    "severity_encode = {'Minor': 1, 'Moderate': 2, 'Extreme': 3}\n",
    "\n",
    "df_select['Type of Admission'] = df_select['Type of Admission'].map(admission_encode)\n",
    "df_select['Severity of Illness'] = df_select['Severity of Illness'].map(severity_encode)\n",
    "\n",
    "df_select['Age'] = df_select['Age'].replace(\n",
    "    {'0-10': 1, '11-20': 2, '21-30': 3, '31-40': 4, '41-50': 5, '51-60': 6, '61-70': 7,\n",
    "     '71-80': 8, '81-90': 9, '91-100': 10})\n",
    "\n",
    "df_select['Stay'] = df_select['Stay'].replace(\n",
    "    {'0-10': 1, '11-20': 2, '21-30': 3, '31-40': 4, '41-50': 5, '51-60': 6, '61-70': 7,\n",
    "     '71-80': 8, '81-90': 9, '91-100': 10, '>100': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_columns = ['Available Extra Rooms in Hospital', 'Bed Grade', 'Visitors with Patient', 'Admission_Deposit',\n",
    "                    'Type of Admission', 'Severity of Illness', 'Age', 'Stay']\n",
    "onehot_columns = ['Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code']\n",
    "other_columns = ['Hospital_code', 'City_Code_Hospital', 'patientid', 'City_Code_Patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def onehot_encode(data, columns):\n",
    "    for column in columns:\n",
    "        dummies = pd.get_dummies(data[column])\n",
    "        data = pd.concat([data, dummies], axis=1)\n",
    "        data.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = onehot_encode(df_select, onehot_columns)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('case_id', inplace=True)\n",
    "\n",
    "y = data['Stay']\n",
    "X = data.drop(['Stay'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_all = X\n",
    "Y_all = y\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, random_state=10, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(Ytrain.shape)\n",
    "print(Ytest.shape)\n",
    "print(X_all.shape)\n",
    "print(Y_all.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # K Fold Cross Validation\n",
    "#\n",
    "# kfold = KFold(n_splits=10, shuffle=True, random_state=10)\n",
    "# Xtrain = list()\n",
    "# Ytrain = list()\n",
    "# for train_index, test_index in kfold.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     Xtrain.append(X.loc[train_index + 1])\n",
    "#     Xtest.append(X.loc[test_index + 1])\n",
    "#     Ytrain.append(y.loc[train_index + 1])\n",
    "#     Ytest.append(y.loc[test_index + 1])\n",
    "# Xtrain\n",
    "# Ytrain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.构建RF模型\n",
    "RFC_ = RandomForestClassifier()  # 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance of feature\n",
    "# c = RFC_.fit(Xtrain, Ytrain).feature_importances_\n",
    "# print(\"Importance: \")\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive feature elimination\n",
    "selector1 = RFE(RFC_, n_features_to_select=0.5, step=1).fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector1.support_.sum()\n",
    "print(selector1.ranking_)\n",
    "print(selector1.n_features_)\n",
    "X_wrapper1 = selector1.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = cross_val_score(RFC_, X_wrapper1, Ytrain).mean()\n",
    "score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of features selected\n",
    "selector1.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature exclusion sort\n",
    "selector1.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_cat_list = selector1.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_cat_list = [True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    False,\n",
    "                    False,\n",
    "                    True,\n",
    "                    True,\n",
    "                    True,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    False,\n",
    "                    True]\n",
    "support_cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.递归特征消除法和曲线图选取最优特征数量\n",
    "score = []  # 建立列表\n",
    "for i in range(12, 22, 1):\n",
    "    X_wrapper = RFE(RFC_, n_features_to_select=i, step=1).fit_transform(Xtrain, Ytrain)\n",
    "    once = cross_val_score(RFC_, X_wrapper, Ytrain).mean()  # 交叉验证\n",
    "    score.append(once)  # 交叉验证结果保存到列表\n",
    "print(max(score), (score.index(max(score)) * 1) + 1)  # 输出最优分类结果和对应的特征数量\n",
    "print(score)\n",
    "plt.figure(figsize=[20, 5])\n",
    "plt.plot(range(1, 17, 1), score)\n",
    "plt.xticks(range(1, 17, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = list(Xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_factor_todrop = []\n",
    "for i in range(38):\n",
    "    if support_cat_list[i] is False:\n",
    "        list_factor_todrop.append(columns_list[i])\n",
    "\n",
    "list_factor_todrop  #需要抛弃的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.drop(list_factor_todrop, axis=1, inplace=True)\n",
    "Xtest.drop(list_factor_todrop, axis=1, inplace=True)\n",
    "X_all.drop(list_factor_todrop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "Xtrain_remove_other = Xtrain.drop(other_columns, axis=1)\n",
    "Xtest_remove_other = Xtest.drop(other_columns, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Xtrain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_remove_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree_classification = DecisionTreeClassifier(criterion='entropy', random_state=10)\n",
    "\n",
    "decision_tree = decision_tree_classification.fit(Xtrain, Ytrain)\n",
    "y_pred_DT = decision_tree.predict(Xtest)\n",
    "\n",
    "accuracy_score(Ytest, y_pred_DT) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_one_hot = label_binarize(Ytest, classes=[1,2,3,4,5,6,7,8,9,10,11])\n",
    "y_one_hot_pred_DT = label_binarize(y_pred_DT, classes=[1,2,3,4,5,6,7,8,9,10,11])\n",
    "y_one_hot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy_score_array = np.ndarray(shape=(1,11), dtype=float)\n",
    "for i in range(11):\n",
    "    accuracy_score_array[0,i] = accuracy_score(y_one_hot[:,i], y_one_hot_pred_DT[:,i])\n",
    "accuracy_score_array.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Ytest, y_pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import interp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "n_classes = 11\n",
    "\n",
    "# 计算每一类的ROC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_one_hot[:, i], y_one_hot_pred_DT[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# # micro（方法二）\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_one_hot.ravel(), y_one_hot_pred_DT.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# macro（方法一）\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "lw=2\n",
    "plt.figure()\n",
    "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#          label='micro-average ROC curve (area = {0:0.2f})'\n",
    "#                ''.format(roc_auc[\"micro\"]),\n",
    "#          color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('multi-calss ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree with HyperParameter adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "paramGrid = dict(\n",
    "    max_depth=range(15),\n",
    "    criterion=[\"gini\", \"entropy\"])\n",
    "dtModel = DecisionTreeClassifier(random_state=10)\n",
    "grid = GridSearchCV(dtModel, paramGrid, cv=10, return_train_score=True)\n",
    "grid.fit(Xtrain, Ytrain)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree_classification = DecisionTreeClassifier(criterion='gini', random_state=10, max_depth=10)\n",
    "\n",
    "decision_tree = decision_tree_classification.fit(Xtrain, Ytrain)\n",
    "y_pred_DT = decision_tree.predict(Xtest)\n",
    "accuracy_score(Ytest, y_pred_DT) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Ytest, y_pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_one_hot = label_binarize(Ytest, classes=[1,2,3,4,5,6,7,8,9,10,11])\n",
    "y_one_hot_pred_DT = label_binarize(y_pred_DT, classes=[1,2,3,4,5,6,7,8,9,10,11])\n",
    "y_one_hot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy_score_array = np.ndarray(shape=(1,11), dtype=float)\n",
    "for i in range(11):\n",
    "    accuracy_score_array[0,i] = accuracy_score(y_one_hot[:,i], y_one_hot_pred_DT[:,i])\n",
    "accuracy_score_array.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import interp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "n_classes = 11\n",
    "\n",
    "# 计算每一类的ROC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_one_hot[:, i], y_one_hot_pred_DT[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# # micro（方法二）\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_one_hot.ravel(), y_one_hot_pred_DT.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# macro（方法一）\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "lw=2\n",
    "plt.figure()\n",
    "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#          label='micro-average ROC curve (area = {0:0.2f})'\n",
    "#                ''.format(roc_auc[\"micro\"]),\n",
    "#          color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('multi-calss ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classification = RandomForestClassifier(random_state=10)\n",
    "\n",
    "rf_model = rf_classification.fit(Xtrain, Ytrain)\n",
    "y_pred_RF = rf_model.predict(Xtest)\n",
    "accuracy_score(Ytest, y_pred_RF) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(Ytest, y_pred_RF))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_one_hot = label_binarize(Ytest, classes=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "y_one_hot_pred_DT = label_binarize(y_pred_DT, classes=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "y_one_hot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy_score_array = np.ndarray(shape=(1, 11), dtype=float)\n",
    "for i in range(11):\n",
    "    accuracy_score_array[0, i] = accuracy_score(y_one_hot[:, i], y_one_hot_pred_DT[:, i])\n",
    "accuracy_score_array.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import interp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "n_classes = 11\n",
    "\n",
    "# 计算每一类的ROC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_one_hot[:, i], y_one_hot_pred_DT[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# micro（方法二）\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_one_hot.ravel(), y_one_hot_pred_DT.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# macro（方法一）\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "lw = 2\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                   ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('multi-calss ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest with HyperParameter adjustment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "paramGrid = dict(\n",
    "    n_estimators=np.linspace(10, 100, 10).astype(int),\n",
    "    max_depth=np.arange(4, 11))\n",
    "rfModel = RandomForestClassifier(random_state=10)\n",
    "grid = GridSearchCV(rfModel, paramGrid, cv=10, return_train_score=True)\n",
    "grid.fit(Xtrain, Ytrain)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classification = RandomForestClassifier(random_state=10, max_depth=10, n_estimators=100)\n",
    "\n",
    "rf_model = rf_classification.fit(Xtrain, Ytrain)\n",
    "y_pred_RF = rf_model.predict(Xtest)\n",
    "accuracy_score(Ytest, y_pred_RF) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Ytest, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Ytest, y_pred_RF, pos_label=11)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlxtend.classifier import LogisticRegression as LR\n",
    "# from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "#\n",
    "# paramGrid = dict(\n",
    "#     penalty=['l1', 'l2'],\n",
    "#     C=[0.1, 1, 10, 100, 1000])\n",
    "# lrModel = LogisticRegression(random_state=10)\n",
    "# grid = GridSearchCV(lrModel, paramGrid, cv=3, return_train_score=True)\n",
    "# grid.fit(Xtrain, Ytrain)\n",
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR = LogisticRegression(fit_intercept=True, C=10, penalty=\"l2\")\n",
    "#\n",
    "# LR.fit(Xtrain, Ytrain)\n",
    "#\n",
    "# y_pred_LR = LR.predict(Xtest)\n",
    "# accuracy_score(Ytest, y_pred_LR) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(Ytest, y_pred_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "#\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(Ytest, y_pred_LR, pos_label=11)\n",
    "# auc = metrics.auc(fpr, tpr)\n",
    "# auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# plt.figure()\n",
    "# lw = 2\n",
    "# plt.plot(fpr, tpr, color='darkorange',\n",
    "#          lw=lw, label='ROC curve (area = %0.2f)' % auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic example')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient boost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GB = GradientBoostingClassifier(random_state=10)\n",
    "\n",
    "GB.fit(Xtrain, Ytrain)\n",
    "y_pred_GB = GB.predict(Xtest)\n",
    "accuracy_score(Ytest, y_pred_GB) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Ytest, y_pred_GB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Ytest, y_pred_GB, pos_label=11)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB = GaussianNB()\n",
    "NB.fit(Xtrain_remove_other, Ytrain)\n",
    "\n",
    "y_pred_NB = NB.predict(Xtest_remove_other)\n",
    "accuracy_score(Ytest, y_pred_NB) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Ytest, y_pred_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Ytest, y_pred_NB, pos_label=11)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_remove_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "Xtrain_num = Xtrain_remove_other[['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit']]\n",
    "Xtrain_cat = Xtrain_remove_other.drop(\n",
    "    ['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit'], axis=1)\n",
    "Xtest_num = Xtest_remove_other[['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit']]\n",
    "Xtest_cat = Xtest_remove_other.drop(['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit'],\n",
    "                                    axis=1)\n",
    "kbs = KBinsDiscretizer(n_bins=5, encode='onehot').fit(Xtrain_num)\n",
    "\n",
    "Xtrain_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_num_1 = pd.cut(Xtrain_num['Available Extra Rooms in Hospital'], 5, labels=False)\n",
    "Xtrain_num_2 = pd.cut(Xtrain_num['Visitors with Patient'], 5, labels=False)\n",
    "Xtrain_num_3 = pd.cut(Xtrain_num['Admission_Deposit'], 5, labels=False)\n",
    "\n",
    "Xtest_num_1 = pd.cut(Xtest_num['Available Extra Rooms in Hospital'], 5, labels=False)\n",
    "Xtest_num_2 = pd.cut(Xtest_num['Visitors with Patient'], 5, labels=False)\n",
    "Xtest_num_3 = pd.cut(Xtest_num['Admission_Deposit'], 5, labels=False)\n",
    "\n",
    "Xtrain_NB = pd.merge(Xtrain_num_1, Xtrain_num_2, left_index=True, right_index=True)\n",
    "Xtrain_NB = pd.merge(Xtrain_NB, Xtrain_num_3, left_index=True, right_index=True)\n",
    "\n",
    "Xtest_NB = pd.merge(Xtest_num_1, Xtest_num_2, left_index=True, right_index=True)\n",
    "Xtest_NB = pd.merge(Xtest_NB, Xtest_num_3, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_NB = pd.DataFrame(scaler.fit_transform(Xtrain_NB), index=Xtrain_NB.index, columns=Xtrain_NB.columns)\n",
    "Xtest_NB = pd.DataFrame(scaler.fit_transform(Xtest_NB), index=Xtest_NB.index, columns=Xtest_NB.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_NB = pd.merge(Xtrain_NB, Xtrain_cat, left_index=True, right_index=True)\n",
    "Xtest_NB = pd.merge(Xtest_NB, Xtest_cat, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB().fit(Xtrain_NB, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_NB = mnb.predict(Xtest_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Ytest, y_pred_NB) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN with HyperParameter adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "paramGrid = dict(\n",
    "    n_neighbors=[10, 50, 300, 500, 1000],\n",
    "    weights=[\"uniform\", \"distance\"])\n",
    "knnModel = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knnModel, paramGrid, cv=3, return_train_score=True)\n",
    "grid.fit(Xtrain_remove_other, Ytrain)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=300, weights='distance')\n",
    "knn.fit(Xtrain_remove_other, Ytrain)\n",
    "y_pred_KNN = knn.predict(Xtest_remove_other)\n",
    "accuracy_score(Ytest, y_pred_KNN) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Ytest, y_pred_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Ytest, y_pred_KNN, pos_label=11)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CATBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cb = CatBoostClassifier(random_state=10, use_best_model=True, iterations=1000)\n",
    "cb.fit(Xtrain, Ytrain, use_best_model=True, verbose=100, eval_set=(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_pred_test = cb.predict(Xtest)\n",
    "accuracy_score(Ytest, cb_pred_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Ytest, cb_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_pred_train = cb.predict(Xtrain)\n",
    "accuracy_score(Ytrain, cb_pred_train) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Ytrain, cb_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_pred_all = cb.predict(X_all)\n",
    "accuracy_score(Y_all, cb_pred_all) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_all, cb_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Ytest, cb_pred_all, pos_label=2)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
